\subsection{Background and Related work:}
	Vocal classification is perceived as one of the challenging tasks in medical field. Many researchers did meaningful work on designing optimal classifiers which can help diagnose vocal diseases from patient's voice record. Some vocal diseases such as neoplasm are notoriously hard to distinguish solely by listening due to noise and subtlety of symptom. 
	Most researchers designed optimal algorithm and ways to extract features in audio classification.
	Vahid Majidnezhad tried artificial neural network with Mel-Frequency-Cepstral-Coefficients as feature vectors to achieve optimal result on vocal pathology classfication\cite{b5}. P. Kukharchik also used wavelet transform with support vector machine to optimize classifiers' performance\cite{b4}. Shih-Hau Fang's team also use deep neural network to train classifier by diving the raw waveform into multiple segments, extract normalized MFCC features from them and feeding them into neural network. They also get optimal result from this\cite{b9}.
	However, there are not any researcher who has explored the multiple-ensemble classification by dividing mul-class classification into multiple binary classification in vocal pathology classification, which is what this paper will explore on. 

	