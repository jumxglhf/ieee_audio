\subsection{Background and Related work:}
	Vocal classification is perceived as one of the challenging tasks in machine learning. In medical field, many researchers conduct meaningful work on designing optimal classifiers which can help diagnose vocal diseases from patient's voice record. Some vocal diseases such as neoplasm are notoriously hard to distinguish solely by listening due to noise and subtlety of symptom. 
	Many researchers designed optimal algorithm and ways to extract features in audio classification.
	Vahid Majidnezhad tried artificial neural network with Mel-Frequency-Cepstral-Coefficients(MFCC), a feature vectors which are multiple frames collectively made up the representation of the power specturm of a sound, to achieve optimal result on vocal pathology classfication\cite{b5}. P. Kukharchik also used wavelet transform with support vector machine to optimize classifiers' performance\cite{b4}. Shih-Hau Fang's team also use deep neural network to train classifier by diving the raw waveform into multiple segments, extract normalized MFCC features from them and feeding them into neural network. They also get optimal result from this\cite{b9}.
	However, even though these methods are proved effective to increase classifiers' performance, there are not any researcher who has explored the multiple-ensemble classification by dividing mul-class classification into multiple binary classification in vocal pathology classification, which is what this paper will explore on. 

	