\section{Results \& Discussion}


We have several different kinds of models including TSVM, SVM, Label Propagation and MILR in our ensemble. 

Table~\ref{tab:1} compares the cross validation results for different models on training set and the results we get for the test samples. We tried one ensemble without the TSVM. We suspect that the there are problems caused by the over calling of normal by TSVM. Then, we changed the TSVM to SVM-RBF. We see an increase in both the sensitivity and specificity but the UAR decreased: the Sensitivity increased by 7.2\% and Specificity increased by 16.0\%, though the Specificity of SVM-RBF is low, the other methods in the ensemble are able to catch those normal cases. However, there is a 4\% decrease in UAR score. We think that the SVM-RBF works better for distinguishing normal examples from pathological examples but the TSVM might work better for classification the different kinds of diseases. One possible reason might be that the two diseases Phonotrauma and Neoplasm are very close and hard to distinguish for SVM-RBF, we can see from Table 1, that the SVM-RBF only have around 70 \% of recall for both classes.

From Table~\ref{tab:2}, we can see some of these works well such as Label Propagation, it is able to detect 69 normal cases, but the MILR is capturing far more normal cases, 257, even with threshold 85\%. There is the same problem with the TSVM, which finds 261 normal cases. However, there is a very high Area under ROC graph for MILR, 0.96, for the training set. It seems that it is difficult to detect the normal cases. So we think that there might be some mismatches between the testing examples and training examples, probably there are some features that are not included in the training examples but appeared in the testing files. For the three different kinds of SVM, it seems that they are all somewhat under calling the normal cases, but the SVM-RBF seems to work pretty well. It is able to find 84 normal samples. The overall ensemble seems to get much closer to the real number of normal samples. The different methods in the ensemble are able to learn different aspects of the samples, which will work better than a single method.


\begin{table*}[!htbp]
	\caption{CROSS VALIDATION AND ACTUAL RESULT}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			 & SVM CV & SVM-RBF CV & MILR CV & with TSVM & with SVM-RBF \\
			\hline
			Sensitivity$^{\mathrm{a}}$  & 88.8\%& 92.1\% & 62.0\% & 82.2 \% & 89.4\% \\
			\hline
			Specificity & 79.5\% & 52.0\%& 82.0\%& 60.0\% & 76.0 \% \\
			\hline
			Volcal palsy recall & 81.0\% &76.0\%& N/A & N/A & N/A \\
			\hline
			Phonotrauma recall & 61.0\% &69.6\%& N/A& N/A& N/A\\
			\hline
			Neoplasm recall & 81.1\% & 72.0\%& N/A& N/A& N/A \\
			\hline
			UAR & 76.40\% &72.53\% & N/A& 64.77\% & 60.67\%\\
			\hline
			\multicolumn{4}{l}{$^{\mathrm{a}}$ Number of correctly predicted pathological / total pathological}
		\end{tabular}
		\label{tab:1}
	\end{center}
\end{table*}

\begin{table*}[!htbp]
	\caption{NUMBER OF NORMAL EXAMPLES PREDICTED IN TEST CASES}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			& Number of Normal & Number of Vocal Paralysis & Number of Phonotrauma & Number of Neoplasm \\
			\hline
			SVM & 56 & 72 &158&52 \\
			\hline
			SVM-With Feature Selection & 65 & 107 & 178  & 59 \\
			\hline
			SVM-RBF & 84 & 89 &184 & 53 \\
			\hline
			MILR & 257 & N/A & N/A& N/A\\
			\hline
			Label Propagation & 69 & 78&156 & 54 \\
			\hline
			TSVM & 261 &193&77&133\\
			\hline
			Ensemble with TSVM & 93&97&144&66\\
			\hline
			Ensemble with SVM-RBF & 74&89&184&53\\
			\hline
			Actual Numbers& 122&N/A&N/A&N/A \\
			\hline
		\end{tabular}
		\label{tab:2}
	\end{center}
\end{table*}


